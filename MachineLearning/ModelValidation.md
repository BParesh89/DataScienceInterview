1. Do you know about Concordance or Lift?
2. What is a ROC curve? Write pseudo-code to generate the data for such a curve.
3. What is AU ROC (AUC)?
4. Which is better Too many false positives or too many false negatives?
5. How would you analyze the performance of the predictions generated by regression models versus classification models?
6. How would you assess logistic regression versus simple linear regression models?
7. How would you check if the regression model fits the data well?
8. How would you know if your model overfits?
9. I have two models of comparable accuracy and computational performance. Which one should I choose for production and why?
10. If you had a categorical dependent variable and a mixture of categorical and continuous independent variables, what algorithms, methods, or tools would you use for analysis?
11. Is it better to have too many false negatives or too many false positives?
12. What criteria would you use while selecting the best model from many different models?
13. What Is the 80/20 rule, and tell me about its importance in model validation.
14. What is the name of the matrix used to evaluate predictive models?
15. What precision and recall are?
16. Which evaluation metrics you know? Something apart from accuracy?
17. Can you explain the difference between a Test Set and a Validation Set?
18. What is 10-Fold CV?
19. What is Cross-Validation?
20. What is the difference between holding out a validation set and doing 10-Fold CV?


